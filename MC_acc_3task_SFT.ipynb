{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rouge + Accuracy (Precision & Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "checkpoint_list = [step for step in range(0, 30860+6172, 6172)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 0: \n",
      "{'rouge1': 0.018881514770593598, 'rouge2': 0.0, 'rougeL': 0.018933011521027786, 'rougeLsum': 0.01892426778391159}\n",
      "{'precision': 0.03, 'recall': 0.0016612903225806453}\n",
      "\n",
      "\n",
      "checkpoint 6172: \n",
      "{'rouge1': 0.7616666666666666, 'rouge2': 0.006666666666666666, 'rougeL': 0.7581666666666667, 'rougeLsum': 0.7590000000000001}\n",
      "{'precision': 0.5091666666666667, 'recall': 0.565}\n",
      "\n",
      "\n",
      "checkpoint 12344: \n",
      "{'rouge1': 0.7667142857142857, 'rouge2': 0.014666666666666668, 'rougeL': 0.765452380952381, 'rougeLsum': 0.7635238095238095}\n",
      "{'precision': 0.5208333333333334, 'recall': 0.555}\n",
      "\n",
      "\n",
      "checkpoint 18516: \n",
      "{'rouge1': 0.85975, 'rouge2': 0.005, 'rougeL': 0.8583333333333333, 'rougeLsum': 0.8606666666666669}\n",
      "{'precision': 0.7791666666666667, 'recall': 0.845}\n",
      "\n",
      "\n",
      "checkpoint 24688: \n",
      "{'rouge1': 0.8213896103896103, 'rouge2': 0.005, 'rougeL': 0.8175129870129869, 'rougeLsum': 0.8194740259740261}\n",
      "{'precision': 0.6575, 'recall': 0.685}\n",
      "\n",
      "\n",
      "checkpoint 30860: \n",
      "{'rouge1': 0.7394458874458874, 'rouge2': 0.016666666666666666, 'rougeL': 0.7298874458874458, 'rougeLsum': 0.7331147186147184}\n",
      "{'precision': 0.535, 'recall': 0.56}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_train = []\n",
    "for checkpoint in checkpoint_list:\n",
    "    print(\"checkpoint {}: \".format(checkpoint))\n",
    "\n",
    "    df_train_comp = pd.read_csv(\"./Completions/{}_train.csv\".format(checkpoint))\n",
    "\n",
    "    df_train_comp[\"precision\"] = None\n",
    "    df_train_comp[\"recall\"] = None\n",
    "\n",
    "    for idx in range(len(df_train_comp)):\n",
    "        comp_true = list(df_train_comp[\"comp_true\"])[idx].replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").split(\",\")\n",
    "        comp_true = [mat.strip() for mat in comp_true]\n",
    "        comp_pred = list(df_train_comp[\"comp_pred\"])[idx].replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").split(\",\")\n",
    "        comp_pred = [mat.strip() for mat in comp_pred]\n",
    "        \n",
    "        count_shared = len(set(comp_true).intersection(comp_pred))\n",
    "        df_train_comp[\"precision\"][idx] = count_shared/len(comp_true)\n",
    "        df_train_comp[\"recall\"][idx]    = count_shared/len(comp_pred)\n",
    "    \n",
    "    # rouge\n",
    "    rouge_results = rouge.compute(predictions=list(df_train_comp[\"comp_pred\"]), \n",
    "                                  references=list(df_train_comp[\"comp_true\"]))\n",
    "    print(rouge_results)\n",
    "\n",
    "    # accuracy\n",
    "    accuracy = {\"precision\": df_train_comp[\"precision\"].mean(),\n",
    "                \"recall\": df_train_comp[\"recall\"].mean()}\n",
    "    print(accuracy)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    df_train_comp.to_csv(\"./Completions/{}_train_metric.csv\".format(checkpoint), index=False)\n",
    "\n",
    "    metrics = dict(rouge_results)\n",
    "    metrics[\"checkpoint\"] = checkpoint\n",
    "    metrics[\"precision\"] = df_train_comp[\"precision\"].mean()\n",
    "    metrics[\"precall\"] = df_train_comp[\"recall\"].mean()\n",
    "    metrics_train.append(metrics)\n",
    "\n",
    "df_metrics_train = pd.DataFrame.from_records(metrics_train)\n",
    "df_metrics_train.to_csv(\"./Completions/metrics_train.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 0: \n",
      "{'rouge1': 0.02078449042210682, 'rouge2': 0.0, 'rougeL': 0.02023851337637743, 'rougeLsum': 0.020493459853571712}\n",
      "{'precision': 0.06, 'recall': 0.0034780423280423274}\n",
      "\n",
      "\n",
      "checkpoint 6172: \n",
      "{'rouge1': 0.7629696969696971, 'rouge2': 0.0, 'rougeL': 0.7619393939393937, 'rougeLsum': 0.7604696969696969}\n",
      "{'precision': 0.545, 'recall': 0.6}\n",
      "\n",
      "\n",
      "checkpoint 12344: \n",
      "{'rouge1': 0.7699999999999998, 'rouge2': 0.016666666666666666, 'rougeL': 0.7659999999999998, 'rougeLsum': 0.7645}\n",
      "{'precision': 0.6091666666666667, 'recall': 0.635}\n",
      "\n",
      "\n",
      "checkpoint 18516: \n",
      "{'rouge1': 0.8228888888888889, 'rouge2': 0.0, 'rougeL': 0.8162222222222223, 'rougeLsum': 0.8222777777777778}\n",
      "{'precision': 0.7275, 'recall': 0.77}\n",
      "\n",
      "\n",
      "checkpoint 24688: \n",
      "{'rouge1': 0.7157554112554112, 'rouge2': 0.01, 'rougeL': 0.714034632034632, 'rougeLsum': 0.7063571428571427}\n",
      "{'precision': 0.54, 'recall': 0.54}\n",
      "\n",
      "\n",
      "checkpoint 30860: \n",
      "{'rouge1': 0.7219754130845679, 'rouge2': 0.03, 'rougeL': 0.7206844399731722, 'rougeLsum': 0.7113551307847081}\n",
      "{'precision': 0.47833333333333333, 'recall': 0.485}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_val = []\n",
    "for checkpoint in checkpoint_list:\n",
    "    print(\"checkpoint {}: \".format(checkpoint))\n",
    "    \n",
    "    df_val_comp = pd.read_csv(\"./Completions/{}_val.csv\".format(checkpoint))\n",
    "\n",
    "    df_val_comp[\"precision\"] = None\n",
    "    df_val_comp[\"recall\"] = None\n",
    "\n",
    "    for idx in range(len(df_val_comp)):\n",
    "        comp_true = list(df_val_comp[\"comp_true\"])[idx].replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").split(\",\")\n",
    "        comp_true = [mat.strip() for mat in comp_true]\n",
    "        comp_pred = list(df_val_comp[\"comp_pred\"])[idx].replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").split(\",\")\n",
    "        comp_pred = [mat.strip() for mat in comp_pred]\n",
    "\n",
    "        count_shared = len(set(comp_true).intersection(comp_pred))\n",
    "        df_val_comp[\"precision\"][idx] = count_shared/len(comp_true)\n",
    "        df_val_comp[\"recall\"][idx]    = count_shared/len(comp_pred)\n",
    "    \n",
    "    # rouge\n",
    "    rouge_results = rouge.compute(predictions=list(df_val_comp[\"comp_pred\"]), \n",
    "                                  references=list(df_val_comp[\"comp_true\"]))\n",
    "    print(rouge_results)\n",
    "\n",
    "    # accuracy\n",
    "    accuracy = {\"precision\": df_val_comp[\"precision\"].mean(),\n",
    "                \"recall\": df_val_comp[\"recall\"].mean()}\n",
    "    print(accuracy)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    df_val_comp.to_csv(\"./Completions/{}_val_metric.csv\".format(checkpoint), index=False)\n",
    "\n",
    "    metrics = dict(rouge_results)\n",
    "    metrics[\"checkpoint\"] = checkpoint\n",
    "    metrics[\"precision\"] = df_val_comp[\"precision\"].mean()\n",
    "    metrics[\"recall\"] = df_val_comp[\"recall\"].mean()\n",
    "    metrics_val.append(metrics)\n",
    "\n",
    "df_metrics_val = pd.DataFrame.from_records(metrics_val)\n",
    "df_metrics_val.to_csv(\"./Completions/metrics_val.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cement_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
